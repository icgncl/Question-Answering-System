{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "e216642_FinalProject_Question_Answering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de2c0f49584d420d95d627a0ed52ebfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c540557eecae45f3b81da34916ddc456",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94966880aa024cada13651fcbda351e2",
              "IPY_MODEL_a8a9db0016c745b5ba7869860c53ee5f"
            ]
          }
        },
        "c540557eecae45f3b81da34916ddc456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94966880aa024cada13651fcbda351e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f566ac6a49c4a77a9ed550d9690a977",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff6534c109bf4cd781d196714a6673a4"
          }
        },
        "a8a9db0016c745b5ba7869860c53ee5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb6220332b444a37a0596ff5aafc66e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.60MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_845878fffd3b4e74854bc165ee564ef0"
          }
        },
        "4f566ac6a49c4a77a9ed550d9690a977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff6534c109bf4cd781d196714a6673a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb6220332b444a37a0596ff5aafc66e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "845878fffd3b4e74854bc165ee564ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "039e358c6980490ebe0ebf1156bb3c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a28a33951ee548029faa340c40a80946",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73bfc6edd3d84b6cb3611dac39d8120d",
              "IPY_MODEL_02df567e45c846878b6edea7934921a4"
            ]
          }
        },
        "a28a33951ee548029faa340c40a80946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73bfc6edd3d84b6cb3611dac39d8120d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8410dfd4402845019f25e746de80edda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8cbbf1e446d4265a9005c19c0cb48ba"
          }
        },
        "02df567e45c846878b6edea7934921a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8989d8a8a9f42cfabed6b5532c0c077",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.99MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87a931db91014b0f8aac06e90a5644ea"
          }
        },
        "8410dfd4402845019f25e746de80edda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8cbbf1e446d4265a9005c19c0cb48ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8989d8a8a9f42cfabed6b5532c0c077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87a931db91014b0f8aac06e90a5644ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e834c3c395f4b96b9356bf3df1808a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98208e0d293a4db78a17cfb9e8dade36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49bb08dc21f9413fb78d8beedfef6123",
              "IPY_MODEL_d9b560be2a23481f9ffb97ce3046bd5e"
            ]
          }
        },
        "98208e0d293a4db78a17cfb9e8dade36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49bb08dc21f9413fb78d8beedfef6123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b186ea6bd7f436cb14b9447c60cf4fb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31fc07e2bc7045a592842c231dcc4a1b"
          }
        },
        "d9b560be2a23481f9ffb97ce3046bd5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79d5ee3599e040d6916539cf0c89a7d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 729B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_457b0cf2877b41f3b0e1a47b2e9a2dc8"
          }
        },
        "7b186ea6bd7f436cb14b9447c60cf4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31fc07e2bc7045a592842c231dcc4a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79d5ee3599e040d6916539cf0c89a7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "457b0cf2877b41f3b0e1a47b2e9a2dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17fe30170055408482636dd89a65b40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_935d6246dcf14937b08014e7be4dbaf3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b158689ec335467c8d5f07beefb9a7a9",
              "IPY_MODEL_a6e77a5326b24b92bcb155f8795bc2f1"
            ]
          }
        },
        "935d6246dcf14937b08014e7be4dbaf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b158689ec335467c8d5f07beefb9a7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f851125f5f284cc6822d5c0f9375c978",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f6e8383003c47429051d905e3a1b7be"
          }
        },
        "a6e77a5326b24b92bcb155f8795bc2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e730e2700bac40418de6ed6b2190fb0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 451/451 [00:00&lt;00:00, 4.86kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_06f5859f97994cf981ac2d6b83814810"
          }
        },
        "f851125f5f284cc6822d5c0f9375c978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f6e8383003c47429051d905e3a1b7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e730e2700bac40418de6ed6b2190fb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "06f5859f97994cf981ac2d6b83814810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e68366f96174a40a3244af5a0960660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3dad12c371b4e8c938a3c6f547f6ff5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea82e570d6404998aee3d901fbb4a089",
              "IPY_MODEL_18554952e6de4bc48ea981247cbdbfd2"
            ]
          }
        },
        "e3dad12c371b4e8c938a3c6f547f6ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea82e570d6404998aee3d901fbb4a089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83781528badc483abac60b416b14052e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 265481570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 265481570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c34bc3c773a4e4db3adadeb187a0e61"
          }
        },
        "18554952e6de4bc48ea981247cbdbfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_583a759121e744908b972cbba76811f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 265M/265M [00:06&lt;00:00, 39.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6aa86eee9524404908c8adf57137c62"
          }
        },
        "83781528badc483abac60b416b14052e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c34bc3c773a4e4db3adadeb187a0e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "583a759121e744908b972cbba76811f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6aa86eee9524404908c8adf57137c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhYs1bM0PTa"
      },
      "source": [
        "This is an question-answering system project for academic papers. In this project, Pre-trained Distilbert is used from Huggingface and it is finetuned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7NUluxqGfWy"
      },
      "source": [
        "The **best model**'s pt is located on https://drive.google.com/uc?export=download&confirm=1Eah&id=1_w8AIn1ET-xbk8SAyrd_qYTgjBxMAqZP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO_MVXE8pRDK"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k80ooFDyq2f"
      },
      "source": [
        "In order to mouth to the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcldY4M8yp6v",
        "outputId": "b16cba6e-b32f-4e1d-da84-b677b373f7c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31A2ysrwYc8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379cc161-f51e-4906-9b32-023fa265c764"
      },
      "source": [
        "model_directory = '/content/model_directory'\n",
        "!mkdir model_directory\n",
        "model_directory_for_drive = '/content/drive/MyDrive/model_directory_for_drive'\n",
        "!mkdir '/content/drive/MyDrive/model_directory_for_drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model_directory’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/model_directory_for_drive’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEeVKjIzJcUN"
      },
      "source": [
        "In this project, huggingface library is used; in order to use them with GoogleColab, we need to first install them with pip command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsc3Zc5EJPW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677186be-6d96-4e9b-8d81-8b254622fc87"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!sudo apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install pdftotext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 28.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/a2/d4e1024c891506e1cee8f9d719d20831bac31cb5b7416983c4d2f65a6287/datasets-1.8.0-py3-none-any.whl (237kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, fsspec, datasets\n",
            "Successfully installed datasets-1.8.0 fsspec-2021.6.1 xxhash-2.0.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 36.7 kB of archives.\n",
            "After this operation, 188 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp0v5 amd64 0.62.0-2ubuntu2.12 [28.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp-dev amd64 0.62.0-2ubuntu2.12 [8,676 B]\n",
            "Fetched 36.7 kB in 0s (91.1 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libpoppler-cpp0v5_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pdftotext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/8d/172052e9d618f6029dee0f8c34143c70b967889d4c4b2f1848c93269c066/pdftotext-2.1.6.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pdftotext\n",
            "  Building wheel for pdftotext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdftotext: filename=pdftotext-2.1.6-cp37-cp37m-linux_x86_64.whl size=54611 sha256=442d4eb37274c6608b4b5df39f9818ca99fd18f66ce3493ec7b8514562361f71\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/70/fb/ef625209e07d2f71c9f9390ddaa6909bfef3b8cc925327d18a\n",
            "Successfully built pdftotext\n",
            "Installing collected packages: pdftotext\n",
            "Successfully installed pdftotext-2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoPwnzsdpT7S"
      },
      "source": [
        "# Impoting Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgjhC4kJZcf"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch as nn\n",
        "import os\n",
        "import gdown # in order to download from google drive\n",
        "import time # in order to count the time\n",
        "import pdftotext # in order to convert PDF to string\n",
        "import re # in order to remove unnecessary spaces in the string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5imVUotj0wMV"
      },
      "source": [
        "# Checking Available Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orIHg22h0yaY",
        "outputId": "2635f2cb-57b0-4bc0-d6d5-ea61ec67e8d8"
      },
      "source": [
        "device = nn.device('cuda') if nn.cuda.is_available() else nn.device('cpu')\n",
        "if nn.cuda.is_available():\n",
        "  print(f\"Available Device is GPU.\")\n",
        "else:\n",
        "  print(f\"Available Device is CPU.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available Device is GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRfEU9Esp5aJ"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly24HpjqQNxP"
      },
      "source": [
        "In this project, Squad dataset is used from Standford University"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o2Cay9kJhi6",
        "outputId": "0866cf3d-af85-4c1f-d4c9-8497d18ee00d"
      },
      "source": [
        "dataset = load_dataset('squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjFfGdDip-yV"
      },
      "source": [
        "Visualizing the Dataset and Its Dictionary Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvhjmwDA0cun",
        "outputId": "367a2116-955c-4ec4-9fa0-81e6904ec01d"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['answers', 'context', 'id', 'question', 'title'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmop5oHbqFFB"
      },
      "source": [
        "Creating each list from dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxpVg58jzXVF"
      },
      "source": [
        "train_contexts = dataset['train']['context']\n",
        "train_questions = dataset['train']['question']\n",
        "train_answers = dataset['train']['answers']\n",
        "val_contexts = dataset['validation']['context']\n",
        "val_questions = dataset['validation']['question']\n",
        "val_answers = dataset['validation']['answers']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqFjzQ6gL8_4"
      },
      "source": [
        "Convert Answer Start-Answer End-Text from List to Int-String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsS8AcT0L37C"
      },
      "source": [
        "for i in range(len(train_answers)):\n",
        "  (train_answers[i]['answer_start']) = (train_answers[i]['answer_start'][0])\n",
        "  (train_answers[i]['text']) = (train_answers[i]['text'][0])\n",
        "\n",
        "for i in range(len(val_answers)):\n",
        "  (val_answers[i]['answer_start']) = (val_answers[i]['answer_start'][0])\n",
        "  (val_answers[i]['text']) = (val_answers[i]['text'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-7qga-uqQ1q"
      },
      "source": [
        "This part adds the end idx to end of the answer, and it is taken from https://gist.github.com/jamescalam/02f63ba35c0573f2c1bd45267a4581ed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1338poBR0Ww9"
      },
      "source": [
        "# TAKEN FROM https://gist.github.com/jamescalam/02f63ba35c0573f2c1bd45267a4581ed\n",
        "\n",
        "def add_end_idx(answers, contexts):\n",
        "    # loop through each answer-context pair\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        # gold_text refers to the answer we are expecting to find in context\n",
        "        gold_text = answer['text']\n",
        "        # we already know the start index\n",
        "        start_idx = answer['answer_start']\n",
        "        start_idx = start_idx\n",
        "        # and ideally this would be the end index...\n",
        "        end_idx = start_idx + len(gold_text)\n",
        "\n",
        "        # ...however, sometimes squad answers are off by a character or two\n",
        "        if context[start_idx:end_idx] == gold_text:\n",
        "            # if the answer is not off :)\n",
        "            answer['answer_end'] = end_idx\n",
        "        else:\n",
        "            # this means the answer is off by 1-2 tokens\n",
        "            for n in [1, 2]:\n",
        "                if context[start_idx-n:end_idx-n] == gold_text:\n",
        "                    answer['answer_start'] = start_idx - n\n",
        "                    answer['answer_end'] = end_idx - n\n",
        "# and apply the function to our two answer lists\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg-fiVBfr-tz"
      },
      "source": [
        "Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdYOABq3r_qk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "de2c0f49584d420d95d627a0ed52ebfb",
            "c540557eecae45f3b81da34916ddc456",
            "94966880aa024cada13651fcbda351e2",
            "a8a9db0016c745b5ba7869860c53ee5f",
            "4f566ac6a49c4a77a9ed550d9690a977",
            "ff6534c109bf4cd781d196714a6673a4",
            "fb6220332b444a37a0596ff5aafc66e1",
            "845878fffd3b4e74854bc165ee564ef0",
            "039e358c6980490ebe0ebf1156bb3c54",
            "a28a33951ee548029faa340c40a80946",
            "73bfc6edd3d84b6cb3611dac39d8120d",
            "02df567e45c846878b6edea7934921a4",
            "8410dfd4402845019f25e746de80edda",
            "b8cbbf1e446d4265a9005c19c0cb48ba",
            "c8989d8a8a9f42cfabed6b5532c0c077",
            "87a931db91014b0f8aac06e90a5644ea",
            "5e834c3c395f4b96b9356bf3df1808a0",
            "98208e0d293a4db78a17cfb9e8dade36",
            "49bb08dc21f9413fb78d8beedfef6123",
            "d9b560be2a23481f9ffb97ce3046bd5e",
            "7b186ea6bd7f436cb14b9447c60cf4fb",
            "31fc07e2bc7045a592842c231dcc4a1b",
            "79d5ee3599e040d6916539cf0c89a7d6",
            "457b0cf2877b41f3b0e1a47b2e9a2dc8"
          ]
        },
        "outputId": "0597b302-92fe-4eb6-c857-1d42462fc3ab"
      },
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased-distilled-squad\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de2c0f49584d420d95d627a0ed52ebfb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "039e358c6980490ebe0ebf1156bb3c54",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e834c3c395f4b96b9356bf3df1808a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGXHptYGsEn6"
      },
      "source": [
        "Encodings for train and validation test are created with the help of Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0trcCVX1XHX"
      },
      "source": [
        "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
        "validation_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUkTmOHhy94v"
      },
      "source": [
        "This part of the function is taken from https://huggingface.co/transformers/custom_datasets.html \n",
        "* It is used for adding start and end positions of tokens "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcxi27VS31ds"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(validation_encodings, val_answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOEdRAERzk6t"
      },
      "source": [
        "# Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnIKaxS0zlrW"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: nn.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Es3b6jJhXx"
      },
      "source": [
        "train_dataset = MyDataset(train_encodings)\n",
        "val_dataset = MyDataset(validation_encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4X5U1zQWhTU"
      },
      "source": [
        "Data Loaders are created with the help of PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aRAKuKiWd5w"
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3riJ_159Vp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2vVLizO0Lis"
      },
      "source": [
        "##Definition of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwk3zoqr0MMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e871092-10df-40cd-f102-7de51b687d9f"
      },
      "source": [
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\") \n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlxuENuP1iEj"
      },
      "source": [
        "##Adam Optimizer with Learning Rate = 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Ggj-e71l4m"
      },
      "source": [
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50zvpBZU6BPL"
      },
      "source": [
        "## Training with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRM1ORs20gaE"
      },
      "source": [
        "I have stopped the training at the beginning of 3rd epoch because validation accuracy has started to decrease and each epoch was lasting approximately 1.5 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znGN4MyYWb-K",
        "outputId": "f72a976b-8836-4408-83fc-925e7bd7659e"
      },
      "source": [
        "for epoch in range(3):\n",
        "    print(\"-------------------\")\n",
        "    print(f\"Epoch : {epoch} is started.\")\n",
        "    start_time = time.time()\n",
        "    ############### Training Process ###############\n",
        "\n",
        "    model.train() # In order to convert model for training process\n",
        "    loss_for_every_epoch = 0  # In order to visualize losses for each epoch\n",
        "    number_of_batch = 0\n",
        "    for each_batch in train_loader:\n",
        "        number_of_batch += 1\n",
        "\n",
        "        optim.zero_grad()\n",
        "\n",
        "        input_ids = each_batch['input_ids'].to(device)\n",
        "        attention_mask = each_batch['attention_mask'].to(device)\n",
        "        start_positions = each_batch['start_positions'].to(device)\n",
        "        end_positions = each_batch['end_positions'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask,\n",
        "                        start_positions=start_positions,\n",
        "                        end_positions=end_positions)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        loss.backward()\n",
        "        loss_for_every_epoch = loss_for_every_epoch + loss.item()\n",
        "        optim.step()\n",
        "\n",
        "    if epoch == 0:\n",
        "      training_loss1 = loss_for_every_epoch\n",
        "      training_loss1 = loss_for_every_epoch/number_of_batch\n",
        "      print(f\"Training_Loss_For_Epoch = 1: {training_loss1}\")\n",
        "      epoch_0_time = time.time()- start_time \n",
        "      print(f\"Epoch 0 - is lasted {epoch_0_time} seconds\")\n",
        "    elif epoch == 1:\n",
        "      training_loss2 = loss_for_every_epoch\n",
        "      training_loss2 = loss_for_every_epoch/number_of_batch\n",
        "      print(f\"Training_Loss_For_Epoch = 2: {training_loss2}\")\n",
        "      epoch_1_time = time.time()- start_time \n",
        "      print(f\"Epoch 1 - is lasted {epoch_1_time} seconds\")\n",
        "    elif epoch == 2:\n",
        "      training_loss3 = loss_for_every_epoch\n",
        "      training_loss3 = loss_for_every_epoch/number_of_batch\n",
        "      print(f\"Training_Loss_For_Epoch = 3: {training_loss3}\")\n",
        "      epoch_2_time = time.time()- start_time \n",
        "      print(f\"Epoch 2 - is lasted {epoch_2_time} seconds\")\n",
        "\n",
        "\n",
        "    # Saving The Model\n",
        "    nn.save(model.state_dict(), os.path.join(model_directory, 'epoch-{}.pt'.format(epoch)))\n",
        "    nn.save(model.state_dict(), os.path.join(model_directory_for_drive, 'epoch-{}-withlr=5e-5.pt'.format(epoch)))\n",
        "\n",
        "\n",
        "    \n",
        "    ############### Validation Process ###############\n",
        "\n",
        "    accuracy = []\n",
        "    model.eval()\n",
        "    for each_batch in val_loader:\n",
        "      with nn.no_grad():\n",
        "        input_ids = each_batch['input_ids'].to(device)\n",
        "        attention_mask = each_batch['attention_mask'].to(device)\n",
        "        start_positions = each_batch['start_positions'].to(device)\n",
        "        end_positions = each_batch['end_positions'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        \n",
        "        start_pos_prediction = nn.argmax(outputs['start_logits'], dim = 1)\n",
        "        end_pos_prediction   = nn.argmax(outputs['end_logits'], dim = 1)\n",
        "\n",
        "        # Append to accuracy list if start positions match with prediction\n",
        "        accuracy.append(((start_positions == start_pos_prediction).sum()/len(start_pos_prediction)).item())\n",
        "        # Append to accuracy list if end positions match with prediction\n",
        "        accuracy.append(((end_positions == end_pos_prediction).sum()/len(end_pos_prediction)).item())\n",
        "\n",
        "    if epoch == 0:\n",
        "      validation_Accuracy1 = sum(accuracy)/len(accuracy)\n",
        "      print(f\"validation_accuracy1: {validation_Accuracy1}\")\n",
        "    elif epoch == 1:\n",
        "      validation_Accuracy2 = sum(accuracy)/len(accuracy)\n",
        "      print(f\"validation_accuracy2: {validation_Accuracy2}\")\n",
        "    elif epoch == 2:\n",
        "      validation_Accuracy3 = sum(accuracy)/len(accuracy)\n",
        "      print(f\"validation_accuracy3: {validation_Accuracy3}\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------\n",
            "Epoch : 0 is started.\n",
            "Training_Loss_For_Epoch = 1: 1.0677542532415696\n",
            "Epoch 0 - is lasted 5114.922166347504 seconds\n",
            "validation_accuracy1: 0.680285552220698\n",
            "-------------------\n",
            "Epoch : 1 is started.\n",
            "Training_Loss_For_Epoch = 2: 0.7863054304770684\n",
            "Epoch 1 - is lasted 5094.442261695862 seconds\n",
            "validation_accuracy2: 0.6691187594463534\n",
            "-------------------\n",
            "Epoch : 2 is started.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ7GG4HM5x9x"
      },
      "source": [
        "# Loading the Best Model for Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-E4RbrGGVDp"
      },
      "source": [
        "Downloading the best model from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "NUxHitHFF-0-",
        "outputId": "03a7917a-5a1a-42cc-9409-d6078264058f"
      },
      "source": [
        "url = 'https://drive.google.com/uc?export=download&confirm=1Eah&id=1_w8AIn1ET-xbk8SAyrd_qYTgjBxMAqZP'\n",
        "output = '/content/bestmodel.pt'\n",
        "gdown.download(url, output, quiet=False) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&confirm=1Eah&id=1_w8AIn1ET-xbk8SAyrd_qYTgjBxMAqZP\n",
            "To: /content/bestmodel.pt\n",
            "265MB [00:01, 173MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/bestmodel.pt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fclqU4evslkU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "17fe30170055408482636dd89a65b40b",
            "935d6246dcf14937b08014e7be4dbaf3",
            "b158689ec335467c8d5f07beefb9a7a9",
            "a6e77a5326b24b92bcb155f8795bc2f1",
            "f851125f5f284cc6822d5c0f9375c978",
            "0f6e8383003c47429051d905e3a1b7be",
            "e730e2700bac40418de6ed6b2190fb0b",
            "06f5859f97994cf981ac2d6b83814810",
            "3e68366f96174a40a3244af5a0960660",
            "e3dad12c371b4e8c938a3c6f547f6ff5",
            "ea82e570d6404998aee3d901fbb4a089",
            "18554952e6de4bc48ea981247cbdbfd2",
            "83781528badc483abac60b416b14052e",
            "9c34bc3c773a4e4db3adadeb187a0e61",
            "583a759121e744908b972cbba76811f9",
            "b6aa86eee9524404908c8adf57137c62"
          ]
        },
        "outputId": "3bbb3db2-92ae-494c-9db7-7a7baf8b2233"
      },
      "source": [
        "best_model_directory = '/content/bestmodel.pt'\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\", return_dict=False)\n",
        "model.load_state_dict(nn.load(best_model_directory, map_location=nn.device('cpu')))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17fe30170055408482636dd89a65b40b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e68366f96174a40a3244af5a0960660",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=265481570.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpIuOLCDzvmt"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDkT80N4x1i"
      },
      "source": [
        "In this project, *A Review Paper on Cloud Computing. International Journal of Advanced Research in Computer Science and Software Engineering* by Srivastava, Priyanshu and Khan, Rizwan is used for testing the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQVFSIf5Jt-9"
      },
      "source": [
        "Downloading the PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "po55Aqj7JD-L",
        "outputId": "00a69e97-395a-45e4-95c4-87497380f114"
      },
      "source": [
        "url = 'https://www.researchgate.net/profile/Rizwan-Khan-27/publication/326073288_A_Review_Paper_on_Cloud_Computing/links/5b3c841fa6fdcc8506eef9de/A-Review-Paper-on-Cloud-Computing.pdf?_sg%5B0%5D=pvwAS7i5EBemqW2sqqs6RHvE3tEt0COVJFzfFR5mMmJHC3n-tk8cwxKEBmoeB8oGK9UVlFIW8YIKawvVkQNeCg.KhuXvVUSRqj_EmEMV3FTPmDqvh5xWg4EtQdgLLvutDEdZpQ-llCT3bW8OW_0k_3Z8JulaSlwA8C8oYUE0K6Drg&_sg%5B1%5D=QFnk9OEV5HupL0QxLa7Oknx1rPG8UJugh896J_ru6cnNTpCCseUIBHEfSQycDnGoOTBn8ncoxWwQCkFLEWAMp0kXNFkvVZ2ZMD8sFxvI9Qta.KhuXvVUSRqj_EmEMV3FTPmDqvh5xWg4EtQdgLLvutDEdZpQ-llCT3bW8OW_0k_3Z8JulaSlwA8C8oYUE0K6Drg&_sg%5B2%5D=pRccRT6x9bicwA6KygPJfnMGfg3-12EZSWuGqSK5iKHYSr5S_8cv0HV75pWbQbw46OYHEwCJr_NLboI.6Q2SxdqlhYDCW--wISJjvgKk53IUvLWfI3UE20-PKeFNJ794BoGPCMA66-UbjV7zyDDmFn446H9K69KZTwTWiA&_iepl='\n",
        "output = '/content/711-1636-1-PB.pdf'\n",
        "gdown.download(url, output, quiet=False) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://www.researchgate.net/profile/Rizwan-Khan-27/publication/326073288_A_Review_Paper_on_Cloud_Computing/links/5b3c841fa6fdcc8506eef9de/A-Review-Paper-on-Cloud-Computing.pdf?_sg%5B0%5D=pvwAS7i5EBemqW2sqqs6RHvE3tEt0COVJFzfFR5mMmJHC3n-tk8cwxKEBmoeB8oGK9UVlFIW8YIKawvVkQNeCg.KhuXvVUSRqj_EmEMV3FTPmDqvh5xWg4EtQdgLLvutDEdZpQ-llCT3bW8OW_0k_3Z8JulaSlwA8C8oYUE0K6Drg&_sg%5B1%5D=QFnk9OEV5HupL0QxLa7Oknx1rPG8UJugh896J_ru6cnNTpCCseUIBHEfSQycDnGoOTBn8ncoxWwQCkFLEWAMp0kXNFkvVZ2ZMD8sFxvI9Qta.KhuXvVUSRqj_EmEMV3FTPmDqvh5xWg4EtQdgLLvutDEdZpQ-llCT3bW8OW_0k_3Z8JulaSlwA8C8oYUE0K6Drg&_sg%5B2%5D=pRccRT6x9bicwA6KygPJfnMGfg3-12EZSWuGqSK5iKHYSr5S_8cv0HV75pWbQbw46OYHEwCJr_NLboI.6Q2SxdqlhYDCW--wISJjvgKk53IUvLWfI3UE20-PKeFNJ794BoGPCMA66-UbjV7zyDDmFn446H9K69KZTwTWiA&_iepl=\n",
            "To: /content/711-1636-1-PB.pdf\n",
            "100%|██████████| 400k/400k [00:00<00:00, 9.73MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/711-1636-1-PB.pdf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFRe49TMrT0D"
      },
      "source": [
        "Converting PDF to string with pdftotext lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UznZmiU1fXL"
      },
      "source": [
        "# Load PDF file\n",
        "with open(\"/content/711-1636-1-PB.pdf\", \"rb\") as f:\n",
        "    pdf = pdftotext.PDF(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oozH8Inq1oie"
      },
      "source": [
        "Manually coverted PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYe8TZA1zy3P"
      },
      "source": [
        "manuel_pdf = [\n",
        "       # First Page\n",
        "       \"\"\"Abstract— Today is the era of Cloud Computing Technology in IT Industries. Cloud computing which is based on\n",
        "Internet has the most powerful architecture of computation. It reckons in of a compilation of integrated and\n",
        "networked hardware, software and internet infrastructure. It has various avails atop grid computing and other\n",
        "computing. In this paper, I have given a brief of evaluation of cloud computing by reviewing more than 30 articles on\n",
        "cloud computing. The outcome of this review signalizes the face of the IT industries before and after the cloud\n",
        "computing.\n",
        "Keywords— Cloud, SaaS, PaaS, IaaS, Cloud Computing.\n",
        "I. INTRODUCTION\n",
        "Like real clouds which are the collection of water molecules, the term ‗cloud‘ in cloud computing is the\n",
        "collection of networks. The user can use the modalities of cloud computing boundlessly whenever demanded. Instead of\n",
        "setting up their own physical infrastructure, the users ordinarily prefer a mediator provider for the service of the internet\n",
        "in cloud computing. The users have to pay only for the services they had used [2]. The workload can be shifted to reduce\n",
        "the workload in cloud computing. A load of service is handled by the networks which forms the cloud that's why the load\n",
        "on local computers is not heavy while running an application [1]. So the requisition of hardware and software at the user\n",
        "side is decreased. All we need to have a web browser to use cloud computing. All we need to have a web browser like\n",
        "chrome to use cloud computing. Following are the key features of cloud computing:\n",
        "I.I Resource Pooling and Elasticity\n",
        "I.II Self-Service and On-Demand Services\n",
        "I.III Pricing\n",
        "I.IV Quality of Service\n",
        "There are three services provided by cloud computing that are Software as a Service (SaaS), Platform as a\n",
        "Service (PaaS) and Infrastructure as a Service (IaaS) [1]. The basic examples of cloud computing which are used by\n",
        "general people in daily life are Facebook, YouTube, Dropbox, and Gmail etc. It offers scalability, flexibility, agility, and\n",
        "simplicity that's why its use is rapidly increasing in the enterprises.\n",
        "Fig 1 Network of Cloud\n",
        "II. EVOLUTION OF CLOUD COMPUTING\n",
        "One day in a speech at MIT around in 1960 John McCarthy indicated that like water and electricity, computing\n",
        "can also be sold like a utility. And in 1999, the Salesforce Company started distributing the applications to the customers \"\"\",\n",
        "       # Second Page\n",
        "       \"\"\"through a convenient website [3]. Amazon Web Services were started by Amazon in 2002 and they were providing the\n",
        "services of storage and computation. In around 2009 big companies like Google, Microsoft, HP, Oracle had started to\n",
        "provide cloud computing services [4]. Nowadays each and every person is using the services of cloud computing in their\n",
        "daily life. For example Google Photos, Google Drive, and iCloud etc. In future cloud computing will become the basic\n",
        "need of IT Industries.\n",
        "Fig 2 Evolution of Cloud Computing\n",
        "III. COMPONENTS OF CLOUD COMPUTING\n",
        "Cloud computing has three basic components as followsIII.I Client Computers: The end user can interact with the cloud using the client computers.\n",
        "III.II Distributed Servers: The servers are distributed among the different places but acts like they as working\n",
        "with each other.\n",
        "III.III Data Centres: Data centres are the compilation of servers.\n",
        "Fig 3 Components\n",
        "IV. SERVICES OF CLOUD COMPUTING\n",
        "IV.I Software as a Service (SaaS): The way of carrying application as a service on the internet is known as\n",
        "software as a service. In place of installing the software on his computer, the user can simply access it via the internet [5].\"\"\",\n",
        "       # Third Page\n",
        "       \"\"\"It makes the user free from managing the complex software and hardware. The SaaS users do not need to buy software or\n",
        "hardware, maintain, and update. The only thing user must have an internet connection and then access to the application\n",
        "is very easy. Example, Microsoft Office 365, Google Apps etc.\n",
        "IV.II Platform as a Service (PaaS): A development environment or platform is given to the consumers as a\n",
        "service in PaaS, upon which user can deploy their own software and coding. The customer has the liberty to construct his\n",
        "own applications that can run on the provider's infrastructure [5]. Product as a service providers offers a predefined\n",
        "composition of operating system and application server to obtain the management capacity of the applications. For\n",
        "example, LAMP (Linux, Apache, MySQL, and PHP), J2EE, Ruby etc.\n",
        "IV.III Infrastructure as a Service (IaaS): Many computing resources are provided by the IaaS in the form of\n",
        "storage, network, operating system, hardware, and storage devices on demand. IaaS users can access the services using a\n",
        "wide area network, such as the internet [5]. For example, a user can create virtual machines by login to the IaaS platform.\n",
        "Fig 4 Cloud Computing Services\n",
        "V. TYPES OF CLOUD COMPUTING\n",
        "V.I Public Cloud: The public cloud is a computing service supplied by the third party providers atop the public\n",
        "internet [6]. These services are available for any user who wants to use them and they have to pay only for the services\n",
        "they consumed.\n",
        "V.II Private Cloud: The computing services provided over the internet or private network come under the\n",
        "private cloud and these services are offered only to the selected users in place of common people [1,6]. A higher security\n",
        "and privacy is delegated by private clouds through the firewall and internal hosting\n",
        ".\n",
        "V.II Hybrid Cloud: Hybrid cloud is the combination of public cloud and private cloud. In the hybrid cloud,\n",
        "each cloud can be managed independently but data and applications can be shared among the clouds in the hybrid cloud\n",
        "[1, 6].\n",
        "VI. BENEFITS OF CLOUD COMPUTING\n",
        "VI.I Cost Saving: In cloud computing users have to only pay for the services they consumed. Maintenance cost\n",
        "is low as user do not need to purchase the infrastructure [2].\n",
        "VI.II Flexibility: Cloud computing is scalable. The rapid scale up and down in the operations of your business\n",
        "may require quick adjustment of hardware and resources so in order to manage this variations cloud computing provide\n",
        "flexibility.\n",
        "VI.III Enhanced Security: Cloud computing provide high security by using the data encryption, strong access\n",
        "controls, key management, and security intelligence.\"\"\",\n",
        "       # Forth Page\n",
        "       \"\"\"In this review paper we described in short the introduction, evolution, types and components of cloud computing\n",
        "and also different approaches of cloud computing and some of its advantages. The application area of cloud computing\n",
        "will continuously be increasing. Today approximately all small and big industries are using cloud computing to manage\n",
        "storage, traffic, hardware requirements. So, it is clear that there is major impact of cloud computing on society and\n",
        "business.\n",
        "ACKNOWLEDGMENT\n",
        "We are thankful to Head of Department Mr. Dilkeshwar Pandey and all the faculty member of the Computer\n",
        "Science and engineering department of ABES Institute of Technology for motivation and encouragement which helped\n",
        "us to complete this review paper.\n",
        "REFERENCES\n",
        "[1] Garrison, G., Kim, S., Wakefield, R.L.: Success Factors for Deploying Cloud Computing. Commun. ACM. 55,\n",
        "62–68 (2012).\n",
        "[2] Herhalt, J., Cochrane, K.: Exploring the Cloud: A Global Study of Governments‘ Adoption of Cloud (2012).\n",
        "[3] Sales force, ―CRM‖, http://www.salesforce.com/.\n",
        "[4] Venters, W., Whitley, E.A.: A Critical Review of Cloud Computing: Researching Desires and Realities. J. Inf.\n",
        "Technol. 27, 179–197 (2012).\n",
        "[5] Yang, H., Tate, M.: A Descriptive Literature Review and Classification of Cloud Computing Research.\n",
        "Commun. Assoc. Inf. Syst. 31 (2012).\n",
        "[6] Marston, S., Li, Z., Bandyopadhyay, S., Zhang, J., Ghalsasi, A.: Cloud computing — The Business Perspective.\n",
        "Decis. Support Syst. 51, 176–189 (2011).\n",
        "ABOUT THE AUTHORS\n",
        "1\n",
        "Priyanshu Srivastava: He is a Scholar in the Computer Science and Engineering Department at ABES\n",
        "Institute of Technology, Ghaziabad, since August‘2015. He is a member in Computer Society of India.\n",
        "2\n",
        "Prof. Rizwan Khan: He is the Assistant Professor in the Computer Science and Engineering Department at\n",
        "ABES Institute of Technology, Ghaziabad.\"\"\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adRD2BDL6KgG"
      },
      "source": [
        "## Choosing the best answer between pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZGjd3pzkbsb"
      },
      "source": [
        "def giveanswer(question, pdf,manuel_pdf):\n",
        "\n",
        "  print(\"-----------------------\")\n",
        "  # In order to compare the answers, two initial value is created\n",
        "  max_start_id = -50\n",
        "  max_end_id = -100\n",
        "  for page in pdf: \n",
        "    page = re.sub(' +', ' ', page) # in order to remove unncessary spaces in PDF\n",
        "    tokenizer_out = tokenizer(question, page, truncation=True, padding=True)\n",
        "    input_ids, attention_mask = tokenizer_out[\"input_ids\"], tokenizer_out[\"attention_mask\"]\n",
        "\n",
        "    # Converting them to tensor because model works with them\n",
        "    input_ids_tensor = nn.tensor([input_ids])\n",
        "    attention_mask = nn.tensor([attention_mask])\n",
        "\n",
        "    output = model(input_ids_tensor, attention_mask)\n",
        "    start_id = nn.argmax(output[0])\n",
        "    end_id = nn.argmax(output[1]) + 1\n",
        "\n",
        "    # In order to compare results for each page's answer\n",
        "    start_id_value = (output[0][0][start_id.item()].item())\n",
        "    end_id_value = (output[1][0][end_id.item()-1].item())\n",
        "    # In order to convert tokens to string\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start_id : end_id] , skip_special_tokens=True))\n",
        "    # If the answer is empty, continue\n",
        "    if answer == \"\":\n",
        "      continue\n",
        "    if (max_start_id + max_end_id) < (start_id_value + end_id_value ):\n",
        "      max_start_id = start_id_value\n",
        "      max_end_id = end_id_value\n",
        "      final_start_id = start_id\n",
        "      final_end_id = end_id\n",
        "      final_answer = answer\n",
        "  \n",
        "  print(f\"Question is {question}\")\n",
        "  print(f\"Automatically converted PDF's answer is -> {final_answer}\")\n",
        "\n",
        "  # In order to compare the answers, two initial value is created\n",
        "  max_start_id = -50\n",
        "  max_end_id = -100\n",
        "  for page in manuel_pdf: \n",
        "    page = re.sub(' +', ' ', page) # in order to remove unncessary spaces in PDF\n",
        "    tokenizer_out = tokenizer(question, page, truncation=True, padding=True)\n",
        "    input_ids, attention_mask = tokenizer_out[\"input_ids\"], tokenizer_out[\"attention_mask\"]\n",
        "\n",
        "    # Converting them to tensor because model works with them\n",
        "    input_ids_tensor = nn.tensor([input_ids])\n",
        "    attention_mask = nn.tensor([attention_mask])\n",
        "\n",
        "    output = model(input_ids_tensor, attention_mask)\n",
        "    start_id = nn.argmax(output[0])\n",
        "    end_id = nn.argmax(output[1]) + 1\n",
        "\n",
        "    # In order to compare results for each page's answer\n",
        "    start_id_value = (output[0][0][start_id.item()].item())\n",
        "    end_id_value = (output[1][0][end_id.item()-1].item())\n",
        "    # In order to convert tokens to string\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start_id : end_id] , skip_special_tokens=True))\n",
        "    # If the answer is empty, continue\n",
        "    if answer == \"\":\n",
        "      continue\n",
        "    if (max_start_id + max_end_id) < (start_id_value + end_id_value ):\n",
        "      max_start_id = start_id_value\n",
        "      max_end_id = end_id_value\n",
        "      final_start_id = start_id\n",
        "      final_end_id = end_id\n",
        "      final_answer_manual = answer\n",
        "    # In order to convert tokens to string\n",
        "  print(f\"Manually converted PDF's answer is -> {final_answer_manual}\")\n",
        "  print(\"-----------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE6Z94tp2t5a"
      },
      "source": [
        "As can be seen from results, model works well on \"what are\" questions on both manuel and automatically converted PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HArp9ZuR1-Ut",
        "outputId": "91eb88d1-c039-4cbd-c45b-11ec3569e9fc"
      },
      "source": [
        "giveanswer(\"What is hybrid cloud?\",pdf,manuel_pdf)\n",
        "giveanswer(\"What are data centers?\",pdf,manuel_pdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "Question is What is hybrid cloud?\n",
            "Automatically converted PDF's answer is -> the combination of public cloud and private cloud\n",
            "Manually converted PDF's answer is -> public cloud and private cloud\n",
            "-----------------------\n",
            "-----------------------\n",
            "Question is What are data centers?\n",
            "Automatically converted PDF's answer is -> data centres are the compilation of servers\n",
            "Manually converted PDF's answer is -> data centres are the compilation of servers\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o050_YO3gXn"
      },
      "source": [
        "As can be seen from results, model especially automatically converted PDF cannot understand \"who\" question, manually converted PDF understands the question however it gives wrong answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mudokBRMgIBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17eed67-7798-4962-a853-15eafdf838eb"
      },
      "source": [
        "giveanswer(\"Who is the author of the paper?\",pdf,manuel_pdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "Question is Who is the author of the paper?\n",
            "Automatically converted PDF's answer is -> priyanshu srivastava rizwan khan tata consultancy services limited abes institute of technology 1 publication 32 citations 61 publications 153 citations see profile see profile some of the authors of this publication are also working on these related projects : cloud computing view project machine learning view project all content following this page was uploaded by rizwan khan\n",
            "Manually converted PDF's answer is -> mr. dilkeshwar pandey\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcFbUV3E4Zno"
      },
      "source": [
        "Again, manually converted PDF works better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO_SG3djgIOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ebe1694-a982-421b-c60b-feeaebf8dedc"
      },
      "source": [
        "giveanswer(\"which service does enable to user can deploy their own software and coding?\",pdf,manuel_pdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------\n",
            "Question is which service does enable to user can deploy their own software and coding?\n",
            "Automatically converted PDF's answer is -> amazon web services\n",
            "Manually converted PDF's answer is -> paas\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}